{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clean&dirty.Musaev (2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv3kophr0V4X"
      },
      "source": [
        "There is a pipeline for task \"clean and dirty\" on Kaggle \n",
        "*   The best accuracy is 0.891\n",
        "*   augmentation + resnet18 + Bagging\n",
        "\n",
        "Main steps:\n",
        "\n",
        "1.   importing libraries\n",
        "2.   removing background of pictures\n",
        "3.   augmentation\n",
        "4.   transforming image to matrix(dim = 2) for BaggingClassifier\n",
        "5.   defining base_estimator - PytorchModel\n",
        "5.   fitting/prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGQU38BW8_WE"
      },
      "source": [
        "###IMPORTING\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pefdRYXPurdU"
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import time\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import sklearn\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "seed = 77\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w1UPj_O0kyY"
      },
      "source": [
        "###setup config file for Kaggle \n",
        "#####For downloading datasets/sending predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M57ka6cYvAbf"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload() \n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c platesv2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VtUAuWUxFg-"
      },
      "source": [
        "!unzip plates.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHr2LZ5Ad-3k"
      },
      "source": [
        "import os\n",
        "!rm -rf train val sample_data test\n",
        "data_root = '/content/plates'\n",
        "!rm -rf /content/plates/.DS_Store\n",
        "!rm -rf /content/plates/train/dirty/.DS_Store\n",
        "!rm -rf /content/plates/train/cleaned/.DS_Store\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHhZOBvP16RE"
      },
      "source": [
        "#Removing background for all pictures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmBbXzCl1_ZN"
      },
      "source": [
        "def show_input(path, title=''):\n",
        "    image = Image.open(path)\n",
        "    plt.imshow(image), plt.axis(\"off\")\n",
        "    plt.title(title)\n",
        "    plt.pause(0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YByXYSWe8kr4"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import imageio\n",
        "\n",
        "\n",
        "def remove_back(listdir):\n",
        "  for j in listdir:\n",
        "    image_bgr = cv2.imread(j)\n",
        "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "    rectangle = (10, 10, image_bgr.shape[1]-20, image_bgr.shape[0]-20)\n",
        "\n",
        "    # Create initial mask\n",
        "    mask = np.zeros(image_rgb.shape[:2], np.uint8)\n",
        "\n",
        "    # Create temporary arrays\n",
        "    bgdModel = np.zeros((1, 65), np.float64)\n",
        "    fgdModel = np.zeros((1, 65), np.float64)\n",
        "\n",
        "    # Run grabCut\n",
        "    cv2.grabCut(image_rgb, mask, rectangle, bgdModel, fgdModel, 10, cv2.GC_INIT_WITH_RECT) \n",
        "\n",
        "    # Create mask where sure and likely backgrounds set to 0, otherwise 1\n",
        "    mask_2 = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\n",
        "\n",
        "    # Multiply image with new mask to subtract background\n",
        "    image_rgb_nobg = image_rgb * mask_2[:, :, np.newaxis]\n",
        "    background = image_rgb - image_rgb_nobg\n",
        "\n",
        "    # Change all pixels in the background that are not black to white\n",
        "    background[np.where((background > [0, 0, 0]).all(axis = 2))] = [255, 255, 255]\n",
        "\n",
        "    #Add the background and the image\n",
        "    out_img = background + image_rgb_nobg   \n",
        "    \n",
        "    imageio.imwrite(j, out_img)\n",
        "\n",
        "train_list = glob.glob('/content/plates/train/*/*.jpg')\n",
        "test_list = glob.glob('/content/plates/test/*.jpg')\n",
        "\n",
        "lists= [train_list, test_list]\n",
        "\n",
        "for j in lists:\n",
        "  remove_back(j)\n",
        "\n",
        "for j in train_list[:10]:\n",
        "  show_input(j)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAn7tS_A3OsM"
      },
      "source": [
        "##Creating train, test directories \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REnIzTByg7ZX"
      },
      "source": [
        "import os\n",
        "import shutil \n",
        "from tqdm import tqdm\n",
        "\n",
        "#Creating\n",
        "train_dir = 'train'\n",
        "test_dir = 'test'\n",
        "\n",
        "class_names = ['cleaned', 'dirty']\n",
        "\n",
        "for class_name in class_names:\n",
        "  os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "\n",
        "\n",
        "#Copying\n",
        "for class_name in class_names:\n",
        "  os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "\n",
        "for class_name in class_names:\n",
        "    source_dir = os.path.join(data_root, 'train', class_name)\n",
        "    for i, file_name in enumerate(tqdm(os.listdir(source_dir))):\n",
        "      dest_dir = os.path.join(train_dir, class_name)  \n",
        "      shutil.copy(os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name))\n",
        "\n",
        "shutil.copytree(os.path.join(data_root, 'test'), os.path.join(test_dir, 'unknown'))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bul9Od_t7-y"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "class CustomNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = torchvision.models.resnet18(pretrained=True)\n",
        "    for param in self.model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    self.model.fc = torch.nn.Sequential(\n",
        "    torch.nn.Linear(self.model.fc.in_features, 512),\n",
        "    torch.nn.BatchNorm1d(512),\n",
        "    #torch.nn.Dropout(p = 0.7),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(512, 256),\n",
        "    torch.nn.BatchNorm1d(256),\n",
        "    #torch.nn.Dropout(p = 0.7),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(256, 2))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.model(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYvCzMOQIFy-"
      },
      "source": [
        "#BAGGING\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_Zx-xv0oxAm"
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "          transforms.RandomPerspective(distortion_scale=0.2, p=0.1, interpolation=3, fill=255),\n",
        "          transforms.RandomChoice([transforms.CenterCrop(180),\n",
        "                                  transforms.CenterCrop(160),\n",
        "                                  transforms.CenterCrop(140),\n",
        "                                  transforms.CenterCrop(120),\n",
        "                                  transforms.Compose([transforms.CenterCrop(280),transforms.Grayscale(3,),]),\n",
        "                                  transforms.Compose([transforms.CenterCrop(200),transforms.Grayscale(3,),])]),\n",
        "          transforms.Resize((224, 224)),\n",
        "          transforms.ColorJitter(contrast=4),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "      ])\n",
        "  \n",
        "val_transforms = transforms.Compose([\n",
        "          transforms.RandomPerspective(distortion_scale=0.2, p=0.1, interpolation=3, fill=255),\n",
        "          transforms.RandomChoice([transforms.CenterCrop(180),\n",
        "                                  transforms.CenterCrop(160),\n",
        "                                  transforms.CenterCrop(140),\n",
        "                                  transforms.CenterCrop(120),\n",
        "                                  transforms.Compose([transforms.CenterCrop(280), transforms.Grayscale(3,),]),\n",
        "                                  transforms.Compose([transforms.CenterCrop(200),transforms.Grayscale(3,),])]),\n",
        "          transforms.Resize((224, 224)),\n",
        "          transforms.ColorJitter(contrast=4),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "      ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-4Ca4MB4XPN"
      },
      "source": [
        "###Creating custom Dataloader class for getting original tuple + path of image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGScNG3W4Mis"
      },
      "source": [
        "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
        "    def __getitem__(self, index):\n",
        "        original_tuple = super().__getitem__(index)\n",
        "        path = self.imgs[index][0]\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5Sa263X4cIi"
      },
      "source": [
        "##Transforming image to matrix(dim = 2) for BaggingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHZP5ZBG4hwQ",
        "outputId": "6e0a9f91-e8aa-4b7c-af65-800cf1e20bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def to_tensor(phase = 'train'):\n",
        "  transforms_in_place = transforms.Compose([\n",
        "          transforms.Resize((224, 224)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "  \n",
        "  if phase == 'train':\n",
        "    train = []\n",
        "    images=glob.glob(\"/content/train/*/*jpg\") \n",
        "    for image in images:\n",
        "      img = Image.open(image)\n",
        "      img = transforms_in_place(img)\n",
        "      train.append((image.split('/')[3], img))\n",
        "    X = np.zeros((0,150528))\n",
        "    y_train = []\n",
        "    for j in train:\n",
        "      y_train.append(j[0])\n",
        "      X = np.concatenate((X,torch.unsqueeze(j[1][:,:,:].reshape(-1), 0)), axis = 0)\n",
        "    Y = []\n",
        "    for j in y_train:\n",
        "      if j == 'dirty':\n",
        "        Y.append(1)\n",
        "      else:\n",
        "        Y.append(0)\n",
        "    return X, Y\n",
        "  \n",
        "  else:\n",
        "    test = []\n",
        "    images=glob.glob(\"/content/test/unknown/*jpg\") \n",
        "    for image in images:\n",
        "      img = Image.open(image)\n",
        "      img = transforms_in_place(img)\n",
        "      test.append(img)\n",
        "    X = np.zeros((0,150528))\n",
        "    for j in test:\n",
        "      X = np.concatenate((X,torch.unsqueeze(j[:,:,:].reshape(-1), 0)), axis = 0)\n",
        "    return X\n",
        "\n",
        "X_train, y_train = to_tensor(phase = 'train')   \n",
        "X_test = to_tensor(phase = 'test')\n",
        "\n",
        "X_train.shape, X_test.shape  # N_samples * 3 * 244 * 244"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40, 150528), (744, 150528))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvLINWRSeml2"
      },
      "source": [
        "##PytorchModel - base_estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA617Q30b6rE"
      },
      "source": [
        "import sklearn\n",
        "class PytorchModel(sklearn.base.BaseEstimator):\n",
        "  def __init__(self, net_type, net_params, optim_type, optim_params, loss_fn,\n",
        "               input_shape, batch_size=20, accuracy_tol=0.02, tol_epochs=10,\n",
        "               cuda=True):\n",
        "    self.net_type = net_type\n",
        "    self.net_params = net_params\n",
        "    self.optim_type = optim_type\n",
        "    self.optim_params = optim_params\n",
        "    self.loss_fn = loss_fn\n",
        "\n",
        "    self.input_shape = input_shape\n",
        "    self.batch_size = batch_size\n",
        "    self.accuracy_tol = accuracy_tol\n",
        "    self.tol_epochs = tol_epochs\n",
        "    self.cuda = cuda\n",
        "    self.scheduler =  torch.optim.lr_scheduler.StepLR\n",
        "\n",
        "  \"\"\"FIT FUNC\"\"\"\n",
        "  def fit(self, X, y):\n",
        "    self.net = self.net_type(**self.net_params)\n",
        "    trainloss = []\n",
        "    trainacc = []\n",
        "    if self.cuda:\n",
        "      self.net = self.net.cuda()\n",
        "    self.optim = self.optim_type(self.net.parameters(), **self.optim_params)\n",
        "    self.schedul = self.scheduler(self.optim, step_size = 5)\n",
        "    uniq_classes = [0,1]\n",
        "    self.classes_ = uniq_classes\n",
        " \n",
        "    \n",
        "    #hack\n",
        "    path = '/content/train'\n",
        "    train_dataset = torchvision.datasets.ImageFolder(path, transform = train_transforms)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=False)\n",
        "    #hack\n",
        "    \n",
        "    last_accuracies = []\n",
        "    epoch = 0\n",
        "    keep_training = True\n",
        "    while keep_training:\n",
        "      self.net.train()\n",
        "      train_samples_count = 0\n",
        "      true_train_samples_count = 0\n",
        "\n",
        "      self.schedul.step()\n",
        "      for batch in train_loader:\n",
        "        x_data, y_data = batch[0], batch[1]\n",
        "        if self.cuda:\n",
        "          x_data = x_data.cuda()\n",
        "          y_data = y_data.cuda()\n",
        "\n",
        "        y_pred = self.net(x_data)\n",
        "        loss = self.loss_fn(y_pred, y_data)\n",
        "\n",
        "        self.optim.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optim.step()\n",
        "\n",
        "        y_pred = y_pred.argmax(dim=1, keepdim=False)\n",
        "        true_classified = (y_pred == y_data).sum().item()\n",
        "        true_train_samples_count += true_classified\n",
        "        train_samples_count += len(x_data)\n",
        "\n",
        "      train_accuracy = true_train_samples_count / train_samples_count\n",
        "      last_accuracies.append(train_accuracy)\n",
        "      print('metrics for epoch', 'loss:',loss, 'acc:',train_accuracy)\n",
        "      trainloss.append(loss)\n",
        "      trainacc.append(train_accuracy)\n",
        "      \n",
        "      if len(last_accuracies) > self.tol_epochs:\n",
        "        last_accuracies.pop(0)\n",
        "\n",
        "      if len(last_accuracies) == self.tol_epochs:\n",
        "        accuracy_difference = max(last_accuracies) - min(last_accuracies)\n",
        "        if accuracy_difference <= self.accuracy_tol:\n",
        "          keep_training = False\n",
        "\n",
        "  \n",
        "  \"\"\"PREDICT FUNC\"\"\"\n",
        "  def predict_proba(self, X, y=None):\n",
        "\n",
        "    #hack\n",
        "    path = '/content/test'\n",
        "    test_dataset = ImageFolderWithPaths(path, val_transforms)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=50,shuffle=False, drop_last=False)\n",
        "    #hack\n",
        "    \n",
        "\n",
        "    self.net.eval()\n",
        "    predictions = []\n",
        "    im_path = []\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "        x_data, y_data, paths = batch[0], batch[1], batch[2]\n",
        "        if self.cuda:\n",
        "          x_data = x_data.cuda()\n",
        "          y_data = y_data.cuda()\n",
        "        im_path.extend(paths)\n",
        "        y_pred = self.net(x_data)\n",
        "\n",
        "        predictions.append(y_pred.detach().cpu().numpy())\n",
        "    #print(im_path)\n",
        "    predictions = np.concatenate(predictions)\n",
        "    return predictions\n",
        "\n",
        "  def predict(self, X, y=None):\n",
        "    predictions = self.predict_proba(X, y)\n",
        "    predictions = predictions.argmax(axis=1)\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95aIp5VeeqWs"
      },
      "source": [
        "#BaggingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT0zXkdRoxNL"
      },
      "source": [
        "base_model = PytorchModel(net_type=CustomNet, net_params=dict(), optim_type=torch.optim.Adam,\n",
        "                          optim_params={\"lr\": 1e-3}, loss_fn=torch.nn.CrossEntropyLoss(),\n",
        "                          input_shape=(3, 224, 224), batch_size=20, accuracy_tol=0.1,\n",
        "                          tol_epochs=10, cuda=True)\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "meta_classifier = BaggingClassifier(base_estimator=base_model, n_estimators=50) \n",
        "meta_classifier.fit(X_train, y_train) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNqK-u6zv4J1"
      },
      "source": [
        "#PEDICTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnDy5p5NG1JN"
      },
      "source": [
        "test_img_paths =  os.listdir('/content/test/unknown/')\n",
        "test_predictions = meta_classifier.predict(X_test)\n",
        "\n",
        "for img, pred in zip(test_img_paths, test_predictions):\n",
        "   show_input(img, title=pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vncsRfvXRiK4"
      },
      "source": [
        "import pandas as pd\n",
        "submission_df = pd.DataFrame.from_dict({'id': test_img_paths, 'label': test_predictions})\n",
        "\n",
        "submission_df['label'] = submission_df['label'].map(lambda pred: 'dirty' if (pred > 0.5) else 'cleaned')\n",
        "submission_df['id'] = submission_df['id'].str.replace('/content/test/unknown/', '')\n",
        "submission_df['id'] = submission_df['id'].str.replace('.jpg', '')\n",
        "submission_df.set_index('id', inplace=True)\n",
        "submission_df.head(n=6)\n",
        "\n",
        "submission_df.to_csv('submission.csv')\n",
        "!kaggle competitions submit platesv2 -f submission.csv -m \"My submission message\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}